{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import os\nimport pandas as pd\nimport seaborn as sns\nDATA_PATH = os.path.join(\"../input\")\n\ndef load_data(fileName, data_path=DATA_PATH):\n    csv_path = os.path.join(data_path, fileName)\n    return pd.read_csv(csv_path)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "59b9fbe9a5d5a2360d8b424bdc8533d130689be0",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_set = load_data(\"train.csv\")\ntest_set = load_data(\"test.csv\")\nexpected_results = load_data(\"gender_submission.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "69e7c5a2e9ce1821b57424da58a20ff22df671b8"
      },
      "cell_type": "code",
      "source": "test_passenger_ids = {'PassengerId':  expected_results[\"PassengerId\"], 'Survived': []}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10d35d87d6e3d10de4d319f5e8df65ce7fc35a79",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_set.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5914cd2c66bc98d57ecdace91ed219d54c45d030",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import seaborn as sns\n\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train_set)\n#Clearly, the passengers in class 1 and 2 were more likely to survive",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8c0c0171363d5a13c72ff03bb1e9a5cfb1a0d9ea"
      },
      "cell_type": "code",
      "source": "train_set[\"Pclass\"] = train_set[\"Pclass\"].fillna('0')\ntest_set[\"Pclass\"] = test_set[\"Pclass\"].fillna('0')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "33f878c0661c933a1b9042dd070a0eea942b72ca",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sns.barplot(x=\"Sex\", y=\"Survived\", data=train_set)\n# Sex of the surviving passengers is also important, as seen in the graph below",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a6a567640058d6e4bc6a635afb68a42114d36c33"
      },
      "cell_type": "code",
      "source": "mean_value = train_set['Age'].mean()\ntrain_set[\"Age\"] = train_set[\"Age\"].fillna(mean_value)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "56e36b5e5dbe5ba77a20d9e6124d4776be75b933"
      },
      "cell_type": "code",
      "source": "mean_value_test = test_set['Age'].mean()\ntest_set[\"Age\"] = test_set[\"Age\"].fillna(mean_value_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ffdac3ecef130c065f7d50d9aa9a56bce2872f6d"
      },
      "cell_type": "code",
      "source": "train_set[\"Embarked\"] = train_set[\"Embarked\"].fillna('X')\ntest_set[\"Embarked\"] = test_set[\"Embarked\"].fillna('X')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d419165ab33ef9054c7524d703ff5cc7ac6b1166"
      },
      "cell_type": "code",
      "source": "bins = (0, 10, 20, 30, 40, 50, 60, 100)\ngroup_names = ['0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60-100']\ntrain_set['Age'] = pd.cut(train_set['Age'], bins = bins, labels = group_names)\ntest_set['Age'] = pd.cut(test_set['Age'], bins = bins, labels = group_names)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6036ff172edb7c0e5439deaa5dcafc098aa81f63",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sns.barplot(x=\"SibSp\", y=\"Survived\", data=train_set)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a9efd7f58666e44951a571a08d7a35f5066e43b7",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sns.barplot(x=\"Parch\", y=\"Survived\", data=train_set)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d3158e72b13f70faaea348469a4d05200cadd84b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sns.barplot(x=\"Embarked\", y=\"Survived\", data=train_set)\n#From the graph below, we can also see that the passengers that embarked in Cherbourg were more likely to survive ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "6d72618205264cb0ff3082916a11fd9fedee0197"
      },
      "cell_type": "code",
      "source": "train_set[\"Fare\"] = train_set[\"Fare\"].fillna(train_set[\"Fare\"].mean())\ntest_set[\"Fare\"] = test_set[\"Fare\"].fillna(test_set[\"Fare\"].mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f235630894bd698a2376da9ccd267704e84ad07a"
      },
      "cell_type": "code",
      "source": "labels = train_set[\"Survived\"]\ntrain_set = train_set.drop([\"Survived\"], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8965105262b1d6c1bf9e1f60cb49446373faf0a9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#\"Parch\", \"SibSp\"\ntrain_set[\"Parch\"].fillna(train_set[\"Parch\"].mean())\ntest_set[\"Parch\"].fillna(test_set[\"Parch\"].mean())\n\ntrain_set[\"SibSp\"].fillna(train_set[\"SibSp\"].mean())\ntest_set[\"SibSp\"].fillna(test_set[\"SibSp\"].mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8b7e59c8e8f369f6e0ee86aec95d405dcbc21667"
      },
      "cell_type": "code",
      "source": "# Definition of the CategoricalEncoder class, copied from PR #9151.\n# Just run this cell, or copy it to your code, do not try to understand it (yet).\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.utils import check_array\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy import sparse\nimport numpy as np\n\nclass CategoricalEncoder(BaseEstimator, TransformerMixin):\n    \"\"\"Encode categorical features as a numeric array.\n    The input to this transformer should be a matrix of integers or strings,\n    denoting the values taken on by categorical (discrete) features.\n    The features can be encoded using a one-hot aka one-of-K scheme\n    (``encoding='onehot'``, the default) or converted to ordinal integers\n    (``encoding='ordinal'``).\n    This encoding is needed for feeding categorical data to many scikit-learn\n    estimators, notably linear models and SVMs with the standard kernels.\n    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n    Parameters\n    ----------\n    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'\n        The type of encoding to use (default is 'onehot'):\n        - 'onehot': encode the features using a one-hot aka one-of-K scheme\n          (or also called 'dummy' encoding). This creates a binary column for\n          each category and returns a sparse matrix.\n        - 'onehot-dense': the same as 'onehot' but returns a dense array\n          instead of a sparse matrix.\n        - 'ordinal': encode the features as ordinal integers. This results in\n          a single column of integers (0 to n_categories - 1) per feature.\n    categories : 'auto' or a list of lists/arrays of values.\n        Categories (unique values) per feature:\n        - 'auto' : Determine categories automatically from the training data.\n        - list : ``categories[i]`` holds the categories expected in the ith\n          column. The passed categories are sorted before encoding the data\n          (used categories can be found in the ``categories_`` attribute).\n    dtype : number type, default np.float64\n        Desired dtype of output.\n    handle_unknown : 'error' (default) or 'ignore'\n        Whether to raise an error or ignore if a unknown categorical feature is\n        present during transform (default is to raise). When this is parameter\n        is set to 'ignore' and an unknown category is encountered during\n        transform, the resulting one-hot encoded columns for this feature\n        will be all zeros.\n        Ignoring unknown categories is not supported for\n        ``encoding='ordinal'``.\n    Attributes\n    ----------\n    categories_ : list of arrays\n        The categories of each feature determined during fitting. When\n        categories were specified manually, this holds the sorted categories\n        (in order corresponding with output of `transform`).\n    Examples\n    --------\n    Given a dataset with three features and two samples, we let the encoder\n    find the maximum value per feature and transform the data to a binary\n    one-hot encoding.\n    >>> from sklearn.preprocessing import CategoricalEncoder\n    >>> enc = CategoricalEncoder(handle_unknown='ignore')\n    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n    ... # doctest: +ELLIPSIS\n    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,\n              encoding='onehot', handle_unknown='ignore')\n    >>> enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()\n    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n           [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n    See also\n    --------\n    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n      integer ordinal features. The ``OneHotEncoder assumes`` that input\n      features take on values in the range ``[0, max(feature)]`` instead of\n      using the unique values.\n    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n      dictionary items (also handles string-valued features).\n    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n      encoding of dictionary items or strings.\n    \"\"\"\n\n    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n                 handle_unknown='error'):\n        self.encoding = encoding\n        self.categories = categories\n        self.dtype = dtype\n        self.handle_unknown = handle_unknown\n\n    def fit(self, X, y=None):\n        \"\"\"Fit the CategoricalEncoder to X.\n        Parameters\n        ----------\n        X : array-like, shape [n_samples, n_feature]\n            The data to determine the categories of each feature.\n        Returns\n        -------\n        self\n        \"\"\"\n\n        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n                        \"or 'ordinal', got %s\")\n            raise ValueError(template % self.handle_unknown)\n\n        if self.handle_unknown not in ['error', 'ignore']:\n            template = (\"handle_unknown should be either 'error' or \"\n                        \"'ignore', got %s\")\n            raise ValueError(template % self.handle_unknown)\n\n        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n                             \" encoding='ordinal'\")\n\n        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n        n_samples, n_features = X.shape\n\n        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n\n        for i in range(n_features):\n            le = self._label_encoders_[i]\n            Xi = X[:, i]\n            if self.categories == 'auto':\n                le.fit(Xi)\n            else:\n                valid_mask = np.in1d(Xi, self.categories[i])\n                if not np.all(valid_mask):\n                    if self.handle_unknown == 'error':\n                        diff = np.unique(Xi[~valid_mask])\n                        msg = (\"Found unknown categories {0} in column {1}\"\n                               \" during fit\".format(diff, i))\n                        raise ValueError(msg)\n                le.classes_ = np.array(np.sort(self.categories[i]))\n\n        self.categories_ = [le.classes_ for le in self._label_encoders_]\n\n        return self\n\n    def transform(self, X):\n        \"\"\"Transform X using one-hot encoding.\n        Parameters\n        ----------\n        X : array-like, shape [n_samples, n_features]\n            The data to encode.\n        Returns\n        -------\n        X_out : sparse matrix or a 2-d array\n            Transformed input.\n        \"\"\"\n        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n        n_samples, n_features = X.shape\n        X_int = np.zeros_like(X, dtype=np.int)\n        X_mask = np.ones_like(X, dtype=np.bool)\n\n        for i in range(n_features):\n            valid_mask = np.in1d(X[:, i], self.categories_[i])\n\n            if not np.all(valid_mask):\n                if self.handle_unknown == 'error':\n                    diff = np.unique(X[~valid_mask, i])\n                    msg = (\"Found unknown categories {0} in column {1}\"\n                           \" during transform\".format(diff, i))\n                    raise ValueError(msg)\n                else:\n                    # Set the problematic rows to an acceptable value and\n                    # continue `The rows are marked `X_mask` and will be\n                    # removed later.\n                    X_mask[:, i] = valid_mask\n                    X[:, i][~valid_mask] = self.categories_[i][0]\n            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n\n        if self.encoding == 'ordinal':\n            return X_int.astype(self.dtype, copy=False)\n\n        mask = X_mask.ravel()\n        n_values = [cats.shape[0] for cats in self.categories_]\n        n_values = np.array([0] + n_values)\n        indices = np.cumsum(n_values)\n\n        column_indices = (X_int + indices[:-1]).ravel()[mask]\n        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n                                n_features)[mask]\n        data = np.ones(n_samples * n_features)[mask]\n\n        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n                                shape=(n_samples, indices[-1]),\n                                dtype=self.dtype).tocsr()\n        if self.encoding == 'onehot-dense':\n            return out.toarray()\n        else:\n            return out",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e97a87c2303dd36a3218924b7ed428dcb9f53dda"
      },
      "cell_type": "code",
      "source": "#Transform non-numerical values\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        return X[self.attribute_names].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "da27ed97d0cd7c1c432aa1a8ca75a95049498aa5"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nnum_attribs = [\"Fare\", \"Parch\", \"SibSp\"]\ncat_attibs = [\"Sex\", \"Pclass\", \"Age\"]\n\nscaler = StandardScaler()\nscaler.fit(train_set['Fare'].values.reshape(-1, 1))\ntrain_set['Fare'] = scaler.transform(train_set['Fare'].values.reshape(-1, 1))\n\nscaler.fit(test_set['Fare'].values.reshape(-1, 1))\ntest_set['Fare'] = scaler.transform(test_set['Fare'].values.reshape(-1, 1))\n\n\nnum_pipeline = Pipeline([\n    ('selector', DataFrameSelector(num_attribs))\n])\n\ncat_pipeline = Pipeline([\n    ('selector', DataFrameSelector(cat_attibs)),\n    ('cat_encoder', CategoricalEncoder(encoding=\"onehot-dense\"))\n])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1ef444972150c03cdecb34f77578c2fd6074db27"
      },
      "cell_type": "code",
      "source": "from sklearn.pipeline import FeatureUnion\n\nfull_pipeline = FeatureUnion(transformer_list=[\n    (\"num_pipeline\", num_pipeline),\n    (\"cat_pipeline\", cat_pipeline)\n])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9e66aa44f4424dc10ca55dd27e8588224325ff65"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(train_set, labels, test_size=0.2, random_state=42)\nprepared_train_data = full_pipeline.fit_transform(X_train)\nprepared_val_data = full_pipeline.fit_transform(X_val)\n\nprepared_test_data = full_pipeline.fit_transform(test_set)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "6bdf3da5351b1547e9ddf03ce605d28814defd32"
      },
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\nimport numpy as np\n\nmodels = [\n    {\n        'model': BernoulliNB(), \n        'model_name': 'BernoulliNB', \n        'params': \n        {\n            'binarize': [binarize for binarize in np.arange(0, 1, 0.01)],\n            'fit_prior': [True, False]\n        },\n        'best_model': None,\n        'accuracy': 0.0\n    },\n    {\n        'model': DecisionTreeClassifier(), \n        'model_name': 'DecisionTreeClassifier', \n        'params': \n        {\n            'splitter': ['best', 'random'],\n            'max_depth': [depth for depth in range(1, 300)],\n            'min_samples_split': [min_samples for min_samples in np.arange(0.01, 1, 0.01)],\n            'min_samples_leaf': [min_leaf for min_leaf in range(1, 10)]\n        },\n        'best_model': None,\n        'accuracy': 0.0\n    },\n    {\n        'model': RandomForestClassifier(), \n        'model_name': 'RandomForestClassifier', \n        'params': \n        {\n            'n_estimators': [n for n in range(1, 300)],\n            'max_depth': [depth for depth in range(1, 300)],\n            'min_samples_split': [min_samples for min_samples in np.arange(0.01, 1, 0.01)],\n            'min_samples_leaf': [min_leaf for min_leaf in range(1, 100)]\n        },\n        'best_model': None,\n        'accuracy': 0.0\n    },\n    {\n        'model': KNeighborsClassifier(), \n        'model_name': 'KNeighborsClassifier', \n        'params': \n        {\n            'n_neighbors': [n for n in range(1, 200)],\n            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n            'leaf_size': [size for size in range(1, 200)]\n        },\n        'best_model': None,\n        'accuracy': 0.0\n    },\n    {\n        'model': SVC(probability=True), \n        'model_name': 'SVC', \n        'params': \n        {\n            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n            'C': [c for c in np.arange(0.1, 1, 0.1)],\n\n        },\n        'best_model': None,\n        'accuracy': 0.0\n    },\n    {\n        'model': SGDClassifier(),\n        'model_name': 'SGD_clf',\n        'params':\n        {\n            'loss': ['hinge', 'modified_huber', 'log', 'squared_hinge', 'squared_loss'],\n            'warm_start': [True, False]\n        },\n        'best_model': None,\n        'accuracy': 0.0\n    }\n]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a72e474cfc92198b3d504c9d72035c4ea6bf5d8e"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\ndef model_selection(X, y, model_info):\n    \"\"\"\n    Test various estimators.\n    \"\"\"    \n\n    rf_random = RandomizedSearchCV(estimator=model_info['model'], param_distributions=model_info['params'])    \n    rf_random.fit(X, y)\n    model_info['best_model'] = rf_random.best_estimator_\n    \n    expected  = y\n    predicted = model_info['best_model'].predict(prepared_val_data)\n    \n    model_info['accuracy'] = accuracy_score(y_val, predicted)\n    \n    print('MSE:', mean_squared_error(y_val, predicted))\n    print('Model:', model_info['model_name'], ',', 'Precision:', (accuracy_score(y_val, predicted)) * 100, '%')\n    print(cross_validate(model_info['model'], model_info['model_name'], X, y))\n\ndef cross_validate(estimator, estimator_name, X, y):\n    scores = cross_val_score(estimator, X, y, scoring='neg_mean_squared_error', cv=10)\n    plot_scores(scores, estimator_name)\n    \ndef plot_scores(scores, estimator_name):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard Deviation:\", scores.std())\n    \ndef get_estimators(accuracy=0.8):\n    best_estimators = [\n        (estimator['best_model'].__class__.__name__, estimator['best_model']) \n        for estimator in models \n        if estimator['accuracy'] > accuracy\n    ]\n    print(best_estimators)\n    return best_estimators",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24ad12ac5e6fb4f9b80c41e44c795f54e3c314b4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "for model in models:\n    model_selection(prepared_train_data, y_train, model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dafb649a0dab51474e65d6d44efa5e4377aca678",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "best_estimators = get_estimators(0.8)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "177ea35a8975887d44734c366f835c31f4f556ae"
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import VotingClassifier\n\nvote_clf = VotingClassifier(\n    estimators=best_estimators,\n    voting='soft'\n)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b75ae1d1d84b8fe992df6b874d83dec47744631c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "vote_clf.fit(prepared_train_data, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "3fa41eaa5a2d8bbe373b15195bcaf433273892f8"
      },
      "cell_type": "code",
      "source": "predictions = vote_clf.predict(prepared_val_data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a6b3b2ad3612f834be7e64aa249b67e0e078a25e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_squared_error\n\nmse = mean_squared_error(y_val, predictions)\nrmse = np.sqrt(mse)\nrmse",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "78d4a89693c97eab1b614665fb253375d3e57e7f"
      },
      "cell_type": "code",
      "source": "final_predictions = vote_clf.predict(prepared_test_data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "3e4bec95b3a9dfed3977e13a22e0258271597c0f"
      },
      "cell_type": "code",
      "source": "test_passenger_ids[\"Survived\"] = final_predictions",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f73c8cb7988aa1a75ba7f7ac3b028ca5b6872fb0"
      },
      "cell_type": "code",
      "source": "df = pd.DataFrame(data = test_passenger_ids)\ndf",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "b22baca6273d8e3e7cef9476664c97981476da78"
      },
      "cell_type": "code",
      "source": "df.to_csv(\"results.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9f94de3b84f785f28515b4027cba84161b0f8cfe"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}